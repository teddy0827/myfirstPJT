{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20241003\n",
    "\n",
    "0. Oncell data이기때문에,  X_reg값을 이용하면 됨. (ADI처럼 KMRC Decorrect하고, MRC_X를 더하는 처리를 할 필요가 없다.)\n",
    "\n",
    "1. K MRC Decorrect 과정은 skip합니다.  (oncell이라서 KMRC Input값 없음)\n",
    "\n",
    "2. -PSM + PointMRC 처리는 skip합니다. (oncell이라서 pointmrc는 값이 없을것이고, psm만 빼주려면 )\n",
    "\n",
    "3. OSR 처리는 합니다. -> oncell residual 확보. \n",
    "\n",
    "4. residual 에서 PSM Input을 decorrect 해야함. \n",
    "★ PSM Input을 decorrect 처리방식을 결정해야함 \n",
    "방법1. PSM RK값을 Fitting해서 구한다음에 residual에서 빼는 방법. \n",
    "방법2. MRC_X를 이용하는 방법.  Oncell data에는 Point MRC가 없을거라서, MRC_X가 곧 PSM Input(부호는 반대)을 의미함 \n",
    "       -> residual에서 MRC_X만큼을 더해주면 됌. \n",
    "\n",
    "\n",
    "우선 방법1로 해봅니다.\n",
    "1. PSM시트에서 RK값 끌어와서 Fitting. \n",
    "2. De-PSM.  ( Oncell Residual에서 PSM Fitting 빼주기 )   residual_x - psm_pred_x = residual_x_depsm \n",
    "3. residual_x_depsm 을 cpe 38para로 모델링. -> ideal_psm \n",
    "4. ideal_psm의 변동을 확인. -> wafer map & m3s값 trend \n",
    "\n",
    "\n",
    "\n",
    "# 20241003(2)\n",
    "\n",
    "psm input이 없는 shot에서는 해당샷을 skip처리해버리고 있음.  ->  no psm shot에 대해서는 0으로 처리해서 계산에 포함시키게 변경\n",
    "\n",
    "# 20241003(3)\n",
    "residual_x_depsm 을 cpe 38para로 모델링. -> ideal_psm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B3N049.1_VH075040_VH075030_20240530171740_11.nau 파일 읽기 성공\n",
      "B3N049.1_VH075040_VH075030_20240530171740_11.nau 파일에 새로운 시트 추가 완료\n",
      "PDS211.1_WF075040_WF075030_20240716235504_11.nau 파일 읽기 성공\n",
      "PDS211.1_WF075040_WF075030_20240716235504_11.nau 파일에 새로운 시트 추가 완료\n",
      "PRQ328.1_WC046040_WC046030_20240430002132_11.nau 파일 읽기 성공\n",
      "PRQ328.1_WC046040_WC046030_20240430002132_11.nau 파일에 새로운 시트 추가 완료\n",
      "2024-10-04 00:44:38 nau파일 전처리 시작.\n",
      "2024-10-04 00:44:44 nau파일 전처리 완료.\n",
      "2024-10-04 00:44:50 OSR Regression 완료.\n",
      "2024-10-04 00:44:57 OSR Fitting, Residual 완료.\n",
      "2024-10-04 00:45:11 PSM Decorrect 완료.\n",
      "2024-10-04 00:45:27 CPE 38para Regression 완료.\n",
      "2024-10-04 00:45:46 CPE_38para Fitting, Residual 완료.\n",
      "2024-10-04 00:45:46 모든 작업이 완료\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from openpyxl import load_workbook\n",
    "import openpyxl\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# nau 파일이 있는 폴더 경로\n",
    "folder_path = 'C:/py_data/nau'\n",
    "\n",
    "\n",
    "################################################ NAU파일제목에서 M_STEP정보 끌어와서 시트에 저장  ########################################\n",
    "\n",
    "# 폴더 내의 모든 파일에 대해 실행\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # 파일 경로 설정\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # 파일인지 확인 (폴더는 제외)\n",
    "    if os.path.isfile(file_path) and file_name.endswith('.nau'):\n",
    "        try:\n",
    "            # 파일 확장자를 임시로 .xlsx로 변경\n",
    "            temp_file_path = file_path.replace('.nau', '.xlsx')\n",
    "            os.rename(file_path, temp_file_path)\n",
    "\n",
    "            # pandas를 이용해 엑셀 파일(유사)을 읽기\n",
    "            excel_data = pd.read_excel(temp_file_path, engine='openpyxl')\n",
    "            print(f\"{file_name} 파일 읽기 성공\")\n",
    "\n",
    "            # 파일명을 \"_\" 기준으로 분할\n",
    "            file_name_without_extension = os.path.splitext(file_name)[0]\n",
    "            split_file_name = file_name_without_extension.split(\"_\")\n",
    "\n",
    "            # 기존 엑셀 파일 열기\n",
    "            workbook = load_workbook(temp_file_path)\n",
    "\n",
    "            # 파일명 시트를 첫 번째로 추가\n",
    "            new_sheet_name = \"FileName\"\n",
    "            if new_sheet_name not in workbook.sheetnames:\n",
    "                new_sheet = workbook.create_sheet(title=new_sheet_name, index=0)  # 첫 번째 시트로 추가\n",
    "            else:\n",
    "                new_sheet = workbook[new_sheet_name]\n",
    "\n",
    "            # 분할된 파일명을 첫 번째 시트에 기록\n",
    "            for col, value in enumerate(split_file_name, start=1):\n",
    "                new_sheet.cell(row=1, column=col, value=value)\n",
    "\n",
    "            # 변경된 파일 저장\n",
    "            workbook.save(temp_file_path)\n",
    "            print(f\"{file_name} 파일에 새로운 시트 추가 완료\")\n",
    "\n",
    "            # 확장자를 다시 .nau로 복원\n",
    "            os.rename(temp_file_path, file_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"{file_name} 파일을 읽는 중 에러 발생: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################ NAU로부터 필요데이터 추출 (전처리) ########################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 추출할 컬럼 위치 설정 (예: 첫 번째 열은 0, 두 번째 열은 1로 인덱스 시작)\n",
    "columns_to_extract = [0, 1, 2, 3, 4, 5, 6, 7]  # Wafer, TEST, DieX, DieY, X_reg, Y_reg, MRC_X, MRC_Y의 열 위치\n",
    "\n",
    "def process_nau_files(folder_path, columns_to_extract):\n",
    "    # 결과를 담을 리스트 생성\n",
    "    combined_rawdata_list = []\n",
    "    combined_trocs_input_list = []\n",
    "    mrc_data_list = []\n",
    "    combined_psm_input_list = []\n",
    "\n",
    "    # 폴더 내 모든 nau 파일에 대해 반복\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.nau'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            \n",
    "            # 필요한 시트만 읽기\n",
    "            rawdata_file = pd.read_excel(file_path, sheet_name='RawData-1')\n",
    "            trocs_input_file = pd.read_excel(file_path, sheet_name='Trocs Input')\n",
    "            psm_input_file = pd.read_excel(file_path, sheet_name='PerShotMRC')\n",
    "\n",
    "            ########### m_step 시트 불러오기 #########################\n",
    "            m_step_file = pd.read_excel(file_path, sheet_name='FileName')\n",
    "\n",
    "            ######################################## RawData-1 전처리 ##################################################\n",
    "            # 지정된 열 추출\n",
    "            extracted_data_raw = rawdata_file.iloc[:, columns_to_extract].copy()\n",
    "\n",
    "            # 'LOT_ID' 값 및 'STEPSEQ' 추출\n",
    "            lot_id_value_raw = rawdata_file.columns[13]\n",
    "            stepseq_value_raw = rawdata_file.iloc[0, 13]\n",
    "            wafer_value_raw = rawdata_file.iloc[0, 0]\n",
    "            p_eqpid__value_raw = rawdata_file.iloc[1, 13]\n",
    "            photo_ppid_value_raw = rawdata_file.iloc[11, 13]\n",
    "            p_time_value_raw = rawdata_file.iloc[2, 13]\n",
    "            m_time_value_raw = rawdata_file.iloc[4, 13]\n",
    "            chuckid_value_raw = rawdata_file.iloc[15, 13]\n",
    "\n",
    "            # 'm_step' 값 추출 및 신규컬럼 추가\n",
    "            m_step_value_raw = m_step_file.columns[1]\n",
    "            extracted_data_raw['M_STEP'] = m_step_value_raw\n",
    "\n",
    "                \n",
    "            # 새로운 컬럼 추가\n",
    "            extracted_data_raw['STEPSEQ'] = stepseq_value_raw\n",
    "            extracted_data_raw['LOT_ID'] = lot_id_value_raw\n",
    "\n",
    "            # 추가 정보 추출 및 컬럼 추가\n",
    "            extracted_data_raw['STEP_PITCH_X'] = rawdata_file.iloc[6, 13]\n",
    "            extracted_data_raw['STEP_PITCH_Y'] = rawdata_file.iloc[7, 13]\n",
    "            extracted_data_raw['MAP_SHIFT_X'] = rawdata_file.iloc[8, 13]\n",
    "            extracted_data_raw['MAP_SHIFT_Y'] = rawdata_file.iloc[9, 13]\n",
    "\n",
    "            # 'coordinate_X', 'coordinate_Y' 매핑\n",
    "            coord_map = rawdata_file[['Test No', 'coordinate_X', 'coordinate_Y']].drop_duplicates(subset='Test No').set_index('Test No')\n",
    "            extracted_data_raw['coordinate_X'] = extracted_data_raw['TEST'].map(coord_map['coordinate_X'])\n",
    "            extracted_data_raw['coordinate_Y'] = extracted_data_raw['TEST'].map(coord_map['coordinate_Y'])\n",
    "                  \n",
    "            # 'wf_x' 및 'wf_y' 계산\n",
    "            extracted_data_raw['wf_x'] = (\n",
    "                extracted_data_raw['DieX'] * extracted_data_raw['STEP_PITCH_X'] +\n",
    "                extracted_data_raw['MAP_SHIFT_X'] + extracted_data_raw['coordinate_X']\n",
    "            )\n",
    "            extracted_data_raw['wf_y'] = (\n",
    "                extracted_data_raw['DieY'] * extracted_data_raw['STEP_PITCH_Y'] +\n",
    "                extracted_data_raw['MAP_SHIFT_Y'] + extracted_data_raw['coordinate_Y']\n",
    "            )\n",
    "\n",
    "            ##### context 정보추가 #####\n",
    "            extracted_data_raw['P_EQPID'] = rawdata_file.iloc[1, 13]\n",
    "            extracted_data_raw['P_TIME'] = rawdata_file.iloc[2, 13]\n",
    "            extracted_data_raw['M_TIME'] = rawdata_file.iloc[4, 13]\n",
    "            extracted_data_raw['Photo_PPID'] = rawdata_file.iloc[11, 13]\n",
    "            extracted_data_raw['Base_EQP1'] = rawdata_file.iloc[12, 13]\n",
    "            extracted_data_raw['ChuckID'] = rawdata_file.iloc[15, 13]\n",
    "            extracted_data_raw['ReticleID'] = rawdata_file.iloc[16, 13]\n",
    "            \n",
    "            \n",
    "\n",
    "            ######## 'Unique_ID'라는 새로운 컬럼 추가   ########  \n",
    "            ## M_TIME 추가(240922)\n",
    "\n",
    "            extracted_data_raw['UNIQUE_ID'] = extracted_data_raw.apply(\n",
    "                lambda row: f\"{row['STEPSEQ']}_{row['P_EQPID']}_{row['Photo_PPID']}_{row['P_TIME']}_{row['M_STEP']}_{row['M_TIME']}_{row['LOT_ID']}_{row['Wafer']}\", axis=1)\n",
    "\n",
    "\n",
    "            # 'Unique_ID2 추가 (TEST, DieX, DieY 추가. 정렬용)\n",
    "            extracted_data_raw['UNIQUE_ID2'] = extracted_data_raw.apply(\n",
    "                lambda row: f\"{row['STEPSEQ']}_{row['P_EQPID']}_{row['Photo_PPID']}_{row['P_TIME']}_{row['M_STEP']}_{row['M_TIME']}_{row['LOT_ID']}_{row['Wafer']}_{row['TEST']}_{row['DieX']}_{row['DieY']} \", axis=1)\n",
    "                      \n",
    "            # 컬럼 순서 재조정\n",
    "            cols_order = [\n",
    "                'UNIQUE_ID', 'UNIQUE_ID2',\n",
    "                'STEPSEQ', 'LOT_ID', 'Wafer', \n",
    "                'P_EQPID', 'Photo_PPID', 'P_TIME', 'M_STEP', 'M_TIME', 'ChuckID', 'ReticleID', 'Base_EQP1', \n",
    "                'TEST', 'DieX', 'DieY',\n",
    "                'X_reg', 'Y_reg', 'MRC_X', 'MRC_Y', \n",
    "                'STEP_PITCH_X', 'STEP_PITCH_Y', 'MAP_SHIFT_X', 'MAP_SHIFT_Y', 'coordinate_X', 'coordinate_Y', 'wf_x', 'wf_y'\n",
    "            ]\n",
    "            extracted_data_raw = extracted_data_raw[cols_order]\n",
    "\n",
    "            # 리스트에 추가\n",
    "            combined_rawdata_list.append(extracted_data_raw)\n",
    "\n",
    "            ######################################## Trocs Input 전처리 ##################################################\n",
    "\n",
    "            trocs_input_file['STEPSEQ'] = stepseq_value_raw\n",
    "            trocs_input_file['LOT_ID'] = lot_id_value_raw\n",
    "            trocs_input_file['Wafer'] = wafer_value_raw\n",
    "            trocs_input_file['P_EQPID'] = p_eqpid__value_raw\n",
    "            trocs_input_file['Photo_PPID'] = photo_ppid_value_raw\n",
    "            trocs_input_file['P_TIME'] = p_time_value_raw \n",
    "            trocs_input_file['M_TIME'] = m_time_value_raw \n",
    "            trocs_input_file['ChuckID'] = chuckid_value_raw\n",
    "            \n",
    "            # 'm_step' 신규컬럼 추가\n",
    "            trocs_input_file['M_STEP'] = m_step_value_raw \n",
    "\n",
    "         \n",
    "            # Trocs Input 데이터프레임에 'Unique_ID'라는 새로운 컬럼 추가\n",
    "            trocs_input_file['UNIQUE_ID'] = trocs_input_file.apply(\n",
    "                lambda row: f\"{row['STEPSEQ']}_{row['P_EQPID']}_{row['Photo_PPID']}_{row['P_TIME']}_{row['M_STEP']}_{row['M_TIME']}_{row['LOT_ID']}_{row['Wafer']}\", axis=1)\n",
    "\n",
    "            # 'Unique_ID2 추가 (DieX(=dCol), DieY(=dRow) 추가. 정렬용)\n",
    "            trocs_input_file['UNIQUE_ID2'] = trocs_input_file.apply(\n",
    "                lambda row: f\"{row['STEPSEQ']}_{row['P_EQPID']}_{row['Photo_PPID']}_{row['P_TIME']}_{row['M_STEP']}_{row['M_TIME']}_{row['LOT_ID']}_{row['Wafer']}_{row['dCol']}_{row['dRow']}\", axis=1)\n",
    "            \n",
    "            # 순서 재조정\n",
    "            # 기존 컬럼 뒤로 밀기 - 순서를 맨 앞으로 추가하는 순서로 재배열\n",
    "            cols_to_insert = ['UNIQUE_ID', 'UNIQUE_ID2', 'STEPSEQ', 'LOT_ID', 'Wafer', 'P_EQPID', 'Photo_PPID', 'P_TIME', 'M_STEP','M_TIME', 'ChuckID']\n",
    "\n",
    "            # 각 컬럼을 지정된 위치에 삽입 (맨 앞에)\n",
    "            for i, col in enumerate(cols_to_insert):\n",
    "                trocs_input_file.insert(i, col, trocs_input_file.pop(col))\n",
    "\n",
    "            # 리스트에 추가\n",
    "            combined_trocs_input_list.append(trocs_input_file)\n",
    "\n",
    "            ######################################## MRC 전처리 ##################################################\n",
    "            \n",
    "            # MRC 데이터 추출을 위해 'RawData-1' 시트를 header=None으로 다시 읽음\n",
    "            rawdata_file_no_header = pd.read_excel(file_path, sheet_name='RawData-1', header=None)\n",
    "\n",
    "            # MRC 데이터 추출\n",
    "            mrc_part1 = rawdata_file_no_header.iloc[0:20, 15:17]\n",
    "            mrc_part2 = rawdata_file_no_header.iloc[22:40, 15:17]\n",
    "            mrc_part = pd.concat([mrc_part1, mrc_part2], ignore_index=True)\n",
    "\n",
    "            # 컬럼 이름 설정\n",
    "            mrc_part.columns = ['K PARA', 'GPM']\n",
    "\n",
    "            # INDEX 컬럼 추가 (1부터 시작하는 순차적 번호)\n",
    "            mrc_part['INDEX'] = range(1, len(mrc_part) + 1)\n",
    "\n",
    "\n",
    "            # 컬럼 추가             \n",
    "            mrc_part['STEPSEQ'] = stepseq_value_raw\n",
    "            mrc_part['LOT_ID'] = lot_id_value_raw\n",
    "            mrc_part['Wafer'] = wafer_value_raw\n",
    "            mrc_part['P_EQPID'] = p_eqpid__value_raw\n",
    "            mrc_part['Photo_PPID'] = photo_ppid_value_raw\n",
    "            mrc_part['P_TIME'] = p_time_value_raw \n",
    "            mrc_part['M_TIME'] = m_time_value_raw \n",
    "            mrc_part['ChuckID'] = chuckid_value_raw\n",
    "\n",
    "            # 'm_step' 신규컬럼 추가\n",
    "            mrc_part['M_STEP'] = m_step_value_raw \n",
    "\n",
    "            # mrc_part 데이터프레임에 'Unique_ID'라는 새로운 컬럼 추가\n",
    "            mrc_part['UNIQUE_ID'] = mrc_part.apply(\n",
    "                lambda row: f\"{row['STEPSEQ']}_{row['P_EQPID']}_{row['Photo_PPID']}_{row['P_TIME']}_{row['M_STEP']}_{row['M_TIME']}_{row['LOT_ID']}_{row['Wafer']}\", axis=1)\n",
    "\n",
    "            # 컬럼 순서 재조정\n",
    "            mrc_cols_order = [\n",
    "                'UNIQUE_ID',\n",
    "                'STEPSEQ', 'LOT_ID', 'Wafer', \n",
    "                'P_EQPID', 'Photo_PPID', 'P_TIME', 'M_STEP','M_TIME', 'ChuckID',  \n",
    "                'K PARA', 'GPM', 'INDEX'\n",
    "            ]\n",
    "            mrc_part = mrc_part[mrc_cols_order]\n",
    "\n",
    "            \n",
    "            # 리스트에 추가\n",
    "            mrc_data_list.append(mrc_part)\n",
    "\n",
    "            \n",
    "            ######################################## PSM 전처리 ##################################################\n",
    "\n",
    "            psm_input_file['STEPSEQ'] = stepseq_value_raw\n",
    "            psm_input_file['LOT_ID'] = lot_id_value_raw\n",
    "            psm_input_file['Wafer'] = wafer_value_raw\n",
    "            psm_input_file['P_EQPID'] = p_eqpid__value_raw\n",
    "            psm_input_file['Photo_PPID'] = photo_ppid_value_raw\n",
    "            psm_input_file['P_TIME'] = p_time_value_raw \n",
    "            psm_input_file['M_TIME'] = m_time_value_raw \n",
    "            psm_input_file['ChuckID'] = chuckid_value_raw\n",
    "\n",
    "            # 'm_step' 신규컬럼 추가\n",
    "            psm_input_file['M_STEP'] = m_step_value_raw \n",
    "\n",
    "            # PSM Input 데이터프레임에 'Unique_ID'라는 새로운 컬럼 추가\n",
    "            psm_input_file['UNIQUE_ID'] = psm_input_file.apply(\n",
    "                lambda row: f\"{row['STEPSEQ']}_{row['P_EQPID']}_{row['Photo_PPID']}_{row['P_TIME']}_{row['M_STEP']}_{row['M_TIME']}_{row['LOT_ID']}_{row['Wafer']}\", axis=1)\n",
    "\n",
    "            # 'Unique_ID2 추가 (DieX(=dCol), DieY(=dRow) 추가. 정렬용)\n",
    "            psm_input_file['UNIQUE_ID2'] = psm_input_file.apply(\n",
    "                lambda row: f\"{row['STEPSEQ']}_{row['P_EQPID']}_{row['Photo_PPID']}_{row['P_TIME']}_{row['M_STEP']}_{row['M_TIME']}_{row['LOT_ID']}_{row['Wafer']}_{row['dCol']}_{row['dRow']}\", axis=1)\n",
    "            \n",
    "            \n",
    "            # 순서 재조정\n",
    "            # 기존 컬럼 뒤로 밀기 - 순서를 맨 앞으로 추가하는 순서로 재배열\n",
    "            cols_to_insert_psm = ['UNIQUE_ID', 'UNIQUE_ID2', 'STEPSEQ', 'LOT_ID', 'Wafer', 'P_EQPID', 'Photo_PPID', 'P_TIME', 'M_STEP','M_TIME', 'ChuckID']\n",
    "\n",
    "            # 각 컬럼을 지정된 위치에 삽입 (맨 앞에)\n",
    "            for i, col in enumerate(cols_to_insert_psm):\n",
    "                psm_input_file.insert(i, col, psm_input_file.pop(col))\n",
    "\n",
    "            # 리스트에 추가\n",
    "            combined_psm_input_list.append(psm_input_file)\n",
    "\n",
    "\n",
    "\n",
    "    # 리스트를 데이터프레임으로 병합\n",
    "    combined_rawdata = pd.concat(combined_rawdata_list, ignore_index=True)\n",
    "    combined_trocs_input = pd.concat(combined_trocs_input_list, ignore_index=True)\n",
    "    mrc_data = pd.concat(mrc_data_list, ignore_index=True)\n",
    "    combined_psm_input = pd.concat(combined_psm_input_list, ignore_index=True)\n",
    "\n",
    "    # 병합 후, UNIQUE_ID기준으로 오름차순 정렬 (내림차순하고 싶으면 ascending=False 옵션 추가하면 됨.) \n",
    "    combined_rawdata = combined_rawdata.sort_values(by=['UNIQUE_ID', 'TEST', 'DieX', 'DieY'])    \n",
    "    combined_trocs_input = combined_trocs_input.sort_values(by=['UNIQUE_ID', 'dCol', 'dRow'])\n",
    "    mrc_data = mrc_data.sort_values(by=['UNIQUE_ID', 'INDEX'])\n",
    "    combined_psm_input = combined_psm_input.sort_values(by=['UNIQUE_ID', 'dCol', 'dRow'])\n",
    "\n",
    "\n",
    "    # 최종 데이터를 엑셀 파일로 저장\n",
    "    with pd.ExcelWriter('output.xlsx') as writer:\n",
    "        combined_rawdata.to_excel(writer, sheet_name='RawData-1', index=False)\n",
    "        combined_trocs_input.to_excel(writer, sheet_name='Trocs Input', index=False)\n",
    "        mrc_data.to_excel(writer, sheet_name='MRC', index=False)\n",
    "        combined_psm_input.to_excel(writer, sheet_name='PerShotMRC', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################### OSR ###########################\n",
    "\n",
    "\n",
    "\n",
    "def multi_lot_regression(df_rawdata):\n",
    "    # UNIQUE_ID별로 그룹화\n",
    "    grouped = df_rawdata.groupby('UNIQUE_ID')\n",
    "\n",
    "    # 회귀분석 결과를 저장할 리스트\n",
    "    wkrk_results = []\n",
    "\n",
    "    # 각 그룹에 대해 처리\n",
    "    for unique_id, group in grouped:\n",
    "        die_x = group['DieX']\n",
    "        die_y = group['DieY']\n",
    "        step_pitch_x = group['STEP_PITCH_X']\n",
    "        step_pitch_y = group['STEP_PITCH_Y']\n",
    "        map_shift_x = group['MAP_SHIFT_X']\n",
    "        map_shift_y = group['MAP_SHIFT_Y']\n",
    "        field_x = group['coordinate_X']\n",
    "        field_y = group['coordinate_Y']\n",
    "        \n",
    "        # 좌표 계산\n",
    "        x = die_x * step_pitch_x + map_shift_x\n",
    "        y = die_y * step_pitch_y + map_shift_y\n",
    "        rx = field_x\n",
    "        ry = field_y\n",
    "\n",
    "        # X_dx, X_dy 행렬 구성\n",
    "        X_dx = np.vstack([\n",
    "            np.ones(len(x)), x/1e6, -y/1e6, (x**2)/1e12, (x*y)/1e12, (y**2)/1e12, (x**3)/1e15, (x**2*y)/1e15, (x*y**2)/1e15, (y**3)/1e15, \n",
    "            rx/1e6, -ry/1e6, (rx**2)/1e9, (rx*ry)/1e9, (ry**2)/1e9, (rx**3)/1e12, (rx**2*ry)/1e12, (rx*ry**2)/1e12, (ry**3)/1e12\n",
    "        ]).T\n",
    "        X_dy = np.vstack([\n",
    "            np.ones(len(y)), y/1e6, x/1e6, (y**2)/1e12, (y*x)/1e12, (x**2)/1e12, (y**3)/1e15, (y**2*x)/1e15, (y*x**2)/1e15, (x**3)/1e15,\n",
    "            ry/1e6, rx/1e6, (ry**2)/1e9, (ry*rx)/1e9, (rx**2)/1e9, (ry**3)/1e12, (ry**2*rx)/1e12, (ry*rx**2)/1e12\n",
    "        ]).T\n",
    "\n",
    "        # 종속변수\n",
    "        Y_dx = group['X_reg']\n",
    "        Y_dy = group['Y_reg']\n",
    "\n",
    "        # 최소자승법으로 계수 계산\n",
    "        coeff_dx = np.linalg.lstsq(X_dx, Y_dx, rcond=None)[0]\n",
    "        coeff_dy = np.linalg.lstsq(X_dy, Y_dy, rcond=None)[0]\n",
    "\n",
    "        # 결과 저장\n",
    "        wkrk_results.append(pd.DataFrame({\n",
    "            'UNIQUE_ID': [unique_id],\n",
    "            'WK1': [coeff_dx[0]],\n",
    "            'WK2': [coeff_dy[0]],\n",
    "            'WK3': [coeff_dx[1]],\n",
    "            'WK4': [coeff_dy[1]],\n",
    "            'WK5': [coeff_dx[2]],\n",
    "            'WK6': [coeff_dy[2]],\n",
    "            'WK7': [coeff_dx[3]],\n",
    "            'WK8': [coeff_dy[3]],\n",
    "            'WK9': [coeff_dx[4]],\n",
    "            'WK10': [coeff_dy[4]],\n",
    "            'WK11': [coeff_dx[5]],\n",
    "            'WK12': [coeff_dy[5]],\n",
    "            'WK13': [coeff_dx[6]],\n",
    "            'WK14': [coeff_dy[6]],\n",
    "            'WK15': [coeff_dx[7]],\n",
    "            'WK16': [coeff_dy[7]],\n",
    "            'WK17': [coeff_dx[8]],\n",
    "            'WK18': [coeff_dy[8]],\n",
    "            'WK19': [coeff_dx[9]],\n",
    "            'WK20': [coeff_dy[9]],\n",
    "            'RK1': [0],\n",
    "            'RK2': [0],\n",
    "            'RK3': [coeff_dx[10]],\n",
    "            'RK4': [coeff_dy[10]],\n",
    "            'RK5': [coeff_dx[11]],\n",
    "            'RK6': [coeff_dy[11]],\n",
    "            'RK7': [coeff_dx[12]],\n",
    "            'RK8': [coeff_dy[12]],\n",
    "            'RK9': [coeff_dx[13]],\n",
    "            'RK10': [coeff_dy[13]],\n",
    "            'RK11': [coeff_dx[14]],\n",
    "            'RK12': [coeff_dy[14]],\n",
    "            'RK13': [coeff_dx[15]],\n",
    "            'RK14': [coeff_dy[15]],\n",
    "            'RK15': [coeff_dx[16]],\n",
    "            'RK16': [coeff_dy[16]],\n",
    "            'RK17': [coeff_dx[17]],\n",
    "            'RK18': [coeff_dy[17]],\n",
    "            'RK19': [coeff_dx[18]],\n",
    "            'RK20': [0],\n",
    "        }))\n",
    "\n",
    "    # 결과 병합\n",
    "    combined_results = pd.concat(wkrk_results, ignore_index=True)\n",
    "    return combined_results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def multi_lot_fitting_residual(df_rawdata, df_coeff):\n",
    "    # UNIQUE_ID별로 그룹화\n",
    "    grouped = df_rawdata.groupby('UNIQUE_ID')\n",
    "    \n",
    "    # 예측 결과를 저장할 리스트\n",
    "    predictions_list = []\n",
    "    \n",
    "    for unique_id, group in grouped:\n",
    "        stepseq = group['STEPSEQ']\n",
    "        lot_id = group['LOT_ID']\n",
    "        wafer = group['Wafer']\n",
    "        p_eqpid = group['P_EQPID']\n",
    "        photo_ppid = group['Photo_PPID']\n",
    "        p_time = group['P_TIME']\n",
    "        m_step = group['M_STEP']\n",
    "        m_time = group['M_TIME']\n",
    "        chuckid = group['ChuckID']\n",
    "        reticleid = group['ReticleID']\n",
    "        base_eqp1 = group['Base_EQP1']\n",
    "        test = group['TEST']\n",
    "        die_x = group['DieX']\n",
    "        die_y = group['DieY']\n",
    "        mrc_x = group['MRC_X']\n",
    "        mrc_y = group['MRC_Y']\n",
    "        step_pitch_x = group['STEP_PITCH_X']\n",
    "        step_pitch_y = group['STEP_PITCH_Y']\n",
    "        map_shift_x = group['MAP_SHIFT_X']\n",
    "        map_shift_y = group['MAP_SHIFT_Y']\n",
    "        coordinate_x = group['coordinate_X']\n",
    "        coordiante_y = group['coordinate_Y']   \n",
    "        wf_x = group['wf_x']\n",
    "        wf_y = group['wf_y']        \n",
    "\n",
    "\n",
    "\n",
    "        x_reg = group['X_reg']\n",
    "        y_reg = group['Y_reg']\n",
    "\n",
    "      \n",
    "        \n",
    "        x = die_x * step_pitch_x + map_shift_x\n",
    "        y = die_y * step_pitch_y + map_shift_y\n",
    "        rx = coordinate_x\n",
    "        ry = coordiante_y\n",
    "\n",
    "        X_dx = np.vstack([\n",
    "            np.ones(len(x)), x/1e6, -y/1e6, (x**2)/1e12, (x*y)/1e12, (y**2)/1e12, (x**3)/1e15, (x**2*y)/1e15, (x*y**2)/1e15, (y**3)/1e15, \n",
    "            rx/1e6, -ry/1e6, (rx**2)/1e9, (rx*ry)/1e9, (ry**2)/1e9, (rx**3)/1e12, (rx**2*ry)/1e12, (rx*ry**2)/1e12, (ry**3)/1e12\n",
    "        ]).T\n",
    "        X_dy = np.vstack([\n",
    "            np.ones(len(y)), y/1e6, x/1e6, (y**2)/1e12, (y*x)/1e12, (x**2)/1e12, (y**3)/1e15, (y**2*x)/1e15, (y*x**2)/1e15, (x**3)/1e15,\n",
    "            ry/1e6, rx/1e6, (ry**2)/1e9, (ry*rx)/1e9, (rx**2)/1e9, (ry**3)/1e12, (ry**2*rx)/1e12, (ry*rx**2)/1e12\n",
    "        ]).T\n",
    "\n",
    "        # 해당 LOT_ID의 계수 추출\n",
    "        coeffs = df_coeff[df_coeff['UNIQUE_ID'] == unique_id].iloc[0]\n",
    "        coeff_dx = coeffs[['WK1','WK3','WK5','WK7','WK9','WK11','WK13','WK15','WK17','WK19','RK3','RK5','RK7','RK9','RK11','RK13','RK15','RK17','RK19']].values.astype(float)\n",
    "        coeff_dy = coeffs[['WK2','WK4','WK6','WK8','WK10','WK12','WK14','WK16','WK18','WK20','RK4','RK6','RK8','RK10','RK12','RK14','RK16','RK18']].values.astype(float)\n",
    "\n",
    "\n",
    "        # 예측값 계산\n",
    "        pred_x = X_dx.dot(coeff_dx)\n",
    "        pred_y = X_dy.dot(coeff_dy)\n",
    "\n",
    "        # 잔차 계산\n",
    "        residual_x = group['X_reg'] - pred_x\n",
    "        residual_y = group['Y_reg'] - pred_y\n",
    "\n",
    "        # 결과 저장\n",
    "        predictions_list.append(pd.DataFrame({\n",
    "            'UNIQUE_ID' : unique_id,\n",
    "            'STEPSEQ' : stepseq, \n",
    "            'LOT_ID' : lot_id,\n",
    "            'Wafer' : wafer, \n",
    "            'P_EQPID' : p_eqpid,\n",
    "            'Photo_PPID' : photo_ppid,\n",
    "            'P_TIME' : p_time,\n",
    "            'M_STEP' : m_step,\n",
    "            'M_TIME' : m_time,\n",
    "            'ChuckID' : chuckid,\n",
    "            'ReticleID' : reticleid,\n",
    "            'Base_EQP1' : base_eqp1,\n",
    "            'TEST' : test,\n",
    "            'DieX' : die_x,\n",
    "            'DieY' : die_y,\n",
    "            'MRC_X' : mrc_x,\n",
    "            'MRC_Y' : mrc_y,\n",
    "            'STEP_PITCH_X' : step_pitch_x,\n",
    "            'STEP_PITCH_Y' : step_pitch_y,\n",
    "            'MAP_SHIFT_X' : map_shift_x,\n",
    "            'MAP_SHIFT_Y' : map_shift_y,\n",
    "            'coordinate_X' : coordinate_x,\n",
    "            'coordinate_Y' : coordiante_y,\n",
    "            'wf_x' : wf_x,\n",
    "            'wf_y' : wf_y,\n",
    "\n",
    "            'X_reg' : x_reg,\n",
    "            'Y_reg' : y_reg,\n",
    "\n",
    "            'pred_x': pred_x,\n",
    "            'pred_y': pred_y,\n",
    "            'residual_x': residual_x,\n",
    "            'residual_y': residual_y,\n",
    "        }))\n",
    "\n",
    "    # 예측 결과 병합\n",
    "    df_predictions = pd.concat(predictions_list, ignore_index=True)\n",
    "    return df_predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################### PSM Input Decorrect ################################ \n",
    "\n",
    "def psm_decorrect(df_residata, df_psm_input):\n",
    "    # 'shot' 별로 데이터를 그룹화 (고유한 lot_id, die_x, die_y 조합)\n",
    "    grouped = df_residata.groupby(['UNIQUE_ID', 'DieX', 'DieY'])\n",
    "\n",
    "    # 예측 결과를 저장할 리스트\n",
    "    psm_input_list = []\n",
    "\n",
    "    # 각 그룹에 대해 연산 수행\n",
    "    for (unique_id, diex, diey), group in grouped:\n",
    "\n",
    "        stepseq = group['STEPSEQ']\n",
    "        lot_id = group['LOT_ID']\n",
    "        wafer = group['Wafer']\n",
    "        p_eqpid = group['P_EQPID']\n",
    "        photo_ppid = group['Photo_PPID']\n",
    "        p_time = group['P_TIME']\n",
    "        m_step = group['M_STEP']\n",
    "        m_time = group['M_TIME']\n",
    "        chuckid = group['ChuckID']\n",
    "        reticleid = group['ReticleID']\n",
    "        base_eqp1 = group['Base_EQP1']\n",
    "        test = group['TEST']\n",
    "        die_x = group['DieX']\n",
    "        die_y = group['DieY']\n",
    "        mrc_x = group['MRC_X']\n",
    "        mrc_y = group['MRC_Y']\n",
    "        step_pitch_x = group['STEP_PITCH_X']\n",
    "        step_pitch_y = group['STEP_PITCH_Y']\n",
    "        map_shift_x = group['MAP_SHIFT_X']\n",
    "        map_shift_y = group['MAP_SHIFT_Y']\n",
    "        coordinate_x = group['coordinate_X']\n",
    "        coordinate_y = group['coordinate_Y']   \n",
    "        wf_x = group['wf_x']\n",
    "        wf_y = group['wf_y']  \n",
    "\n",
    "        x_reg = group['X_reg']\n",
    "        y_reg = group['Y_reg']\n",
    "        pred_x = group['pred_x']\n",
    "        pred_y = group['pred_y']\n",
    "        residual_x = group['residual_x']\n",
    "        residual_y = group['residual_y']\n",
    "\n",
    "        \n",
    "        # 독립변수 설정 ('coordinate_X', 'coordinate_Y'를 독립변수로 사용)\n",
    "        rx = group['coordinate_X'].values\n",
    "        ry = group['coordinate_Y'].values\n",
    "\n",
    "        # 독립 변수 배열구성\n",
    "        X_dx = np.vstack([\n",
    "            np.ones(len(rx)),\n",
    "            (rx)/1e6,     (-ry)/1e6, \n",
    "            (rx**2)/1e9,  (rx*ry)/1e9,     (ry**2)/1e9,\n",
    "            (rx**3)/1e12, (rx**2*ry)/1e12, (rx*ry**2)/1e12,    (ry**3)/1e12,\n",
    "            (rx**4)/1e19, (rx**3*ry)/1e19, (rx**2*ry**2)/1e19, (rx*ry**3)/1e19,    (ry**4)/1e19,\n",
    "            (rx**5)/1e23, (rx**4*ry)/1e23, (rx**3*ry**2)/1e23, (rx**2*ry**3)/1e23, (rx*ry**4)/1e23,    (ry**5)/1e23,\n",
    "            (rx**6)/1e27, (rx**5*ry)/1e27, (rx**4*ry**2)/1e27, (rx**3*ry**3)/1e27, (rx**2*ry**4)/1e27, (rx*ry**5)/1e27,    (ry**6)/1e27,\n",
    "            (rx**7)/1e31, (rx**6*ry)/1e31, (rx**5*ry**2)/1e31, (rx**4*ry**3)/1e31, (rx**3*ry**4)/1e31, (rx**2*ry**8)/1e31, (rx*ry**6)/1e31, (ry**7)/1e31\n",
    "        ]).T\n",
    "\n",
    "        X_dy = np.vstack([\n",
    "            np.ones(len(ry)), \n",
    "            (ry)/1e6,     (rx)/1e6,\n",
    "            (ry**2)/1e9,  (ry*rx)/1e9,     (rx**2)/1e9,\n",
    "            (ry**3)/1e12, (ry**2*rx)/1e12, (ry*rx**2)/1e12,    (rx**3)/1e12,\n",
    "            (ry**4)/1e19, (ry**3*rx)/1e19, (ry**2*rx**2)/1e19, (ry*rx**3)/1e19,    (rx**4)/1e19,\n",
    "            (ry**5)/1e23, (ry**4*rx)/1e23, (ry**3*rx**2)/1e23, (ry**2*rx**3)/1e23, (ry*rx**4)/1e23,    (rx**5)/1e23,\n",
    "            (ry**6)/1e27, (ry**5*rx)/1e27, (ry**4*rx**2)/1e27, (ry**3*rx**3)/1e27, (ry**2*rx**4)/1e27, (ry*rx**5)/1e27,    (rx**6)/1e27,\n",
    "            (ry**7)/1e31, (ry**6*rx)/1e31, (ry**5*rx**2)/1e31, (ry**4*rx**3)/1e31, (ry**3*rx**4)/1e31, (ry**2*rx**8)/1e31, (ry*rx**6)/1e31, (rx**7)/1e31    \n",
    "            \n",
    "        ]).T\n",
    "\n",
    "\n",
    "        # 종속변수 설정 ( PSM INPUT의 RK값을 독립변수로 사용)\n",
    "        # PerShotMRC 시트에서 해당 UNIQUE_ID에 해당하는 rk1~rk72 값을 추출\n",
    "        psm_row = df_psm_input[(df_psm_input['UNIQUE_ID'] == unique_id) & (df_psm_input['dCol'] == diex) & (df_psm_input['dRow'] == diey)]\n",
    "\n",
    "        if psm_row.empty:\n",
    "            # PSM input이 없는 경우 0으로 처리\n",
    "            Y_dx = np.zeros(36)  # 홀수 rk값의 수만큼 0 배열 생성\n",
    "            Y_dy = np.zeros(36)  # 짝수 rk값의 수만큼 0 배열 생성\n",
    "        else:\n",
    "            # 홀수 rk 값 (Y_dx)과 짝수 rk 값 (Y_dy) 추출\n",
    "            rk_values = psm_row.iloc[:, 15:87]  # rk1 ~ rk72 열을 선택      \n",
    "\n",
    "            # Y_dx는 rk1부터 rk71까지 홀수 열을 추출\n",
    "            Y_dx = rk_values.iloc[:, ::2].values.flatten()       \n",
    "\n",
    "            # Y_dy는 rk2부터 rk72까지 짝수 열을 추출\n",
    "            Y_dy = rk_values.iloc[:, 1::2].values.flatten()  \n",
    "\n",
    "\n",
    "        # 행렬 곱을 통해 예측 값 계산\n",
    "        psm_fit_x = X_dx.dot(Y_dx)\n",
    "        psm_fit_y = X_dy.dot(Y_dy)       \n",
    "\n",
    "        residual_x_depsm = group['residual_x'] - psm_fit_x\n",
    "        residual_y_depsm = group['residual_y'] - psm_fit_y\n",
    "\n",
    "        # 결과 저장\n",
    "        psm_input_list.append(pd.DataFrame({\n",
    "            'UNIQUE_ID': unique_id,\n",
    "            'STEPSEQ' : stepseq, \n",
    "            'LOT_ID' : lot_id,\n",
    "            'Wafer' : wafer, \n",
    "            'P_EQPID' : p_eqpid,\n",
    "            'Photo_PPID' : photo_ppid,\n",
    "            'P_TIME' : p_time,\n",
    "            'M_STEP' : m_step,\n",
    "            'M_TIME' : m_time,\n",
    "            'ChuckID' : chuckid,\n",
    "            'ReticleID' : reticleid,\n",
    "            'Base_EQP1' : base_eqp1,\n",
    "            'TEST' : test,\n",
    "            'DieX' : die_x,\n",
    "            'DieY' : die_y,\n",
    "            'MRC_X' : mrc_x,\n",
    "            'MRC_Y' : mrc_y,\n",
    "            'STEP_PITCH_X' : step_pitch_x,\n",
    "            'STEP_PITCH_Y' : step_pitch_y,\n",
    "            'MAP_SHIFT_X' : map_shift_x,\n",
    "            'MAP_SHIFT_Y' : map_shift_y,\n",
    "            'coordinate_X' : coordinate_x,\n",
    "            'coordinate_Y' : coordinate_y,\n",
    "            'wf_x' : wf_x,\n",
    "            'wf_y' : wf_y,\n",
    "            'X_reg' : x_reg,\n",
    "            'Y_reg' : y_reg,\n",
    "            'pred_x': pred_x,\n",
    "            'pred_y': pred_y,\n",
    "            'residual_x': residual_x,\n",
    "            'residual_y': residual_y,\n",
    "\n",
    "            'psm_fit_x': psm_fit_x,\n",
    "            'psm_fit_y': psm_fit_y,\n",
    "            'residual_x_depsm' : residual_x_depsm,\n",
    "            'residual_y_depsm' : residual_y_depsm\n",
    "               \n",
    "        }))\n",
    "\n",
    "\n",
    "    \n",
    "    # 결과 병합\n",
    "    df_psm_de = pd.concat(psm_input_list, ignore_index=True)\n",
    "    # 정렬 (★ 기존데이터의 정렬순서와 맞춰주기위한 작업)\n",
    "    df_psm_de = df_psm_de.sort_values(by=['UNIQUE_ID', 'TEST', 'DieX', 'DieY'])\n",
    "    return df_psm_de\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################### resi_depsm 을 CPE 19para 모델링 ################################ \n",
    "\n",
    "\n",
    "\n",
    "def resi_to_cpe(df_resi_depsm):\n",
    "    # 'shot' 별로 데이터를 그룹화 (고유한 die_x, die_y 조합)\n",
    "    grouped = df_resi_depsm.groupby(['UNIQUE_ID', 'DieX', 'DieY'])\n",
    "    \n",
    "    # 회귀분석 결과를 저장할 리스트\n",
    "    shot_regression_results = []\n",
    "\n",
    "    for (unique_id, die_x, die_y), group in grouped:\n",
    "        # 독립변수와 종속변수 설정 \n",
    "        # 독립변수 (shot 좌표)\n",
    "        rx = group['coordinate_X']\n",
    "        ry = group['coordinate_Y']  \n",
    "\n",
    "        # 종속변수 (residual)\n",
    "        Yx = group['residual_x_depsm']\n",
    "        Yy = group['residual_y_depsm']\n",
    "\n",
    "\n",
    "\n",
    "        # 독립 변수 배열구성 ( 38PARA )\n",
    "        X_dx = np.vstack([\n",
    "            np.ones(len(rx)),\n",
    "            (rx)/1e6,     (-ry)/1e6, \n",
    "            (rx**2)/1e9,  (rx*ry)/1e9,     (ry**2)/1e9,\n",
    "            (rx**3)/1e12, (rx**2*ry)/1e12, (rx*ry**2)/1e12,    (ry**3)/1e12,\n",
    "\n",
    "        ]).T\n",
    "\n",
    "        X_dy = np.vstack([\n",
    "            np.ones(len(ry)), \n",
    "            (ry)/1e6,     (rx)/1e6,\n",
    "            (ry**2)/1e9,  (ry*rx)/1e9,     (rx**2)/1e9,\n",
    "            (ry**3)/1e12, (ry**2*rx)/1e12, (ry*rx**2)/1e12,    \n",
    "            \n",
    "        ]).T\n",
    "        \n",
    "\n",
    "\n",
    "        coeff_dx = np.linalg.lstsq(X_dx, Yx, rcond=None)[0]\n",
    "        coeff_dy = np.linalg.lstsq(X_dy, Yy, rcond=None)[0]\n",
    "\n",
    "\n",
    "        # 회귀분석 결과를 리스트에 저장\n",
    "        shot_regression_results.append({\n",
    "            'UNIQUE_ID': unique_id,\n",
    "            'DieX': die_x,\n",
    "            'DieY': die_y,\n",
    "            'RK1': coeff_dx[0],\n",
    "            'RK2': coeff_dy[0],\n",
    "            'RK3': coeff_dx[1],\n",
    "            'RK4': coeff_dy[1],\n",
    "            'RK5': coeff_dx[2],\n",
    "            'RK6': coeff_dy[2],\n",
    "\n",
    "            'RK7': coeff_dx[3],\n",
    "            'RK8': coeff_dy[3],\n",
    "            'RK9': coeff_dx[4],\n",
    "            'RK10': coeff_dy[4],\n",
    "            'RK11': coeff_dx[5],\n",
    "            'RK12': coeff_dy[5],\n",
    "            'RK13': coeff_dx[6],\n",
    "            'RK14': coeff_dy[6],\n",
    "            'RK15': coeff_dx[7],\n",
    "            'RK16': coeff_dy[7],\n",
    "            'RK17': coeff_dx[8],\n",
    "            'RK18': coeff_dy[8],\n",
    "            'RK19': coeff_dx[9],\n",
    "            'RK20': 0,            \n",
    "        })\n",
    "    \n",
    "    # 회귀분석 결과를 새로운 DataFrame으로 변환\n",
    "    df_cpe19p = pd.DataFrame(shot_regression_results)\n",
    "    return df_cpe19p\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################### CPE 19para을 fitting (=Ideal PSM) ################################ \n",
    "\n",
    "def cpe38p_fitting(df_resi_depsm, df_cpe19p):\n",
    "    # 결과를 저장할 리스트 생성\n",
    "    predictions_list = []\n",
    "\n",
    "    # 각 데이터 포인트에 대해 처리\n",
    "    for idx, row in df_resi_depsm.iterrows():\n",
    "        \n",
    "        unique_id = row['UNIQUE_ID']\n",
    "        die_x = row['DieX']\n",
    "        die_y = row['DieY']\n",
    "        coordinate_x = row['coordinate_X']\n",
    "        coordinate_y = row['coordinate_Y']\n",
    "        residual_x_depsm = row['residual_x_depsm']\n",
    "        residual_y_depsm = row['residual_y_depsm']\n",
    "        psm_fit_x = row['psm_fit_x']\n",
    "        psm_fit_y = row['psm_fit_y']\n",
    "\n",
    "\n",
    "        \n",
    "        rx = coordinate_x\n",
    "        ry = coordinate_y\n",
    "\n",
    "        # 해당 LOT_ID, DieX, DieY에 해당하는 회귀계수 찾기\n",
    "        coeffs = df_cpe19p[(df_cpe19p['UNIQUE_ID'] == unique_id) & (df_cpe19p['DieX'] == die_x) & (df_cpe19p['DieY'] == die_y)]\n",
    "        \n",
    "        if not coeffs.empty:\n",
    "            coeffs = coeffs.iloc[0]\n",
    "            # 회귀계수 추출\n",
    "            RK1 = coeffs['RK1']\n",
    "            RK2 = coeffs['RK2']\n",
    "            RK3 = coeffs['RK3']\n",
    "            RK4 = coeffs['RK4']\n",
    "            RK5 = coeffs['RK5']\n",
    "            RK6 = coeffs['RK6']\n",
    "            RK7 = coeffs['RK7']\n",
    "            RK8 = coeffs['RK8']\n",
    "            RK9 = coeffs['RK9']\n",
    "            RK10 = coeffs['RK10']\n",
    "            RK11 = coeffs['RK11']\n",
    "            RK12 = coeffs['RK12']\n",
    "            RK13 = coeffs['RK13']\n",
    "            RK14 = coeffs['RK14']\n",
    "            RK15 = coeffs['RK15']\n",
    "            RK16 = coeffs['RK16']\n",
    "            RK17 = coeffs['RK17']\n",
    "            RK18 = coeffs['RK18']\n",
    "            RK19 = coeffs['RK19']\n",
    "            RK20 = coeffs['RK20']\n",
    "\n",
    "                        \n",
    "            \n",
    "            # 예측값 계산\n",
    "            cpe19p_pred_x = (RK1 \n",
    "            + RK3*(rx/1e6) + RK5*(-ry/1e6) \n",
    "            + RK7*(rx**2)/1e9 + RK9*(rx*ry)/1e9 + RK11*(ry**2)/1e9 \n",
    "            + RK13*(rx**3)/1e12 + RK15*(rx**2*ry)/1e12 + RK17*(rx*ry**2)/1e12 + RK19*(ry**3)/1e12 )\n",
    "            \n",
    "\n",
    "            cpe19p_pred_y = (RK2 \n",
    "            + RK4*(ry/1e6) + RK6*(rx/1e6)\n",
    "            + RK8*(ry**2)/1e9 + RK10*(ry*rx)/1e9 + RK12*(rx**2)/1e9\n",
    "            + RK14*(ry**3)/1e12 + RK16*(ry**2*rx)/1e12 + RK18*(ry*rx**2)/1e12 + RK20*(rx**3)/1e12 )\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "            # CPE 잔차값 계산\n",
    "            cpe19p_resi_x = residual_x_depsm - cpe19p_pred_x \n",
    "            cpe19p_resi_y = residual_y_depsm - cpe19p_pred_y\n",
    "\n",
    "            # 결과 저장\n",
    "            predictions_list.append({\n",
    "                'psm_fit_x': psm_fit_x,\n",
    "                'psm_fit_y': psm_fit_y,\n",
    "                'residual_x_depsm': residual_x_depsm,\n",
    "                'residual_y_depsm': residual_y_depsm,\n",
    "                'cpe19p_pred_x': cpe19p_pred_x,\n",
    "                'cpe19p_pred_y': cpe19p_pred_y,\n",
    "                'cpe19p_resi_x': cpe19p_resi_x,\n",
    "                'cpe19p_resi_y': cpe19p_resi_y\n",
    "            })\n",
    "        else:\n",
    "            # 해당하는 회귀계수가 없을 경우 NaN 처리\n",
    "            predictions_list.append({\n",
    "                'cpe19p_pred_x': np.nan,\n",
    "                'cpe19p_pred_y': np.nan,\n",
    "                'cpe19p_resi_x': np.nan,\n",
    "                'cpe19p_resi_y': np.nan\n",
    "            })\n",
    "    \n",
    "    # 결과를 DataFrame으로 변환\n",
    "    df_predictions = pd.DataFrame(predictions_list)\n",
    "    # 원본 데이터와 병합\n",
    "    df_resi_depsm = pd.concat([df_residata.reset_index(drop=True), df_predictions], axis=1)\n",
    "    return df_resi_depsm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################### nau 파일 처리 및 데이터 저장 #####################################################################\n",
    "\n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'nau파일 전처리 시작.')\n",
    "process_nau_files(folder_path, columns_to_extract)\n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'nau파일 전처리 완료.')\n",
    "\n",
    "\n",
    "\n",
    "################################### MULTI LOT REGRESSION #####################################################################\n",
    "\n",
    "# 데이터 불러오기\n",
    "df_rawdata = pd.read_excel(\"output.xlsx\", sheet_name='RawData-1')\n",
    "\n",
    "# 회귀분석 수행\n",
    "df_coeff = multi_lot_regression(df_rawdata)\n",
    "\n",
    "# 결과를 엑셀 파일에 저장\n",
    "with pd.ExcelWriter('output.xlsx', engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    df_coeff.to_excel(writer, sheet_name='OSR_K', index=False)\n",
    "\n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'OSR Regression 완료.')\n",
    "\n",
    "################################### MULTI LOT FITTING, RESIDUAL #####################################################################\n",
    "\n",
    "# 잔차 계산\n",
    "df_predictions = multi_lot_fitting_residual(df_rawdata, df_coeff)\n",
    "\n",
    "# 예측 결과를 엑셀 파일에 저장\n",
    "with pd.ExcelWriter('output.xlsx', engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    df_predictions.to_excel(writer, sheet_name='OSR_raw_fit_resi', index=False)\n",
    "\n",
    "    \n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'OSR Fitting, Residual 완료.')\n",
    "\n",
    "\n",
    "################################### PSM Input Decorrect #####################################################################\n",
    "\n",
    "\n",
    "# 데이타 불러오기 \n",
    "df_psm_input = pd.read_excel('output.xlsx', sheet_name='PerShotMRC')\n",
    "df_residata = pd.read_excel('output.xlsx', sheet_name='OSR_raw_fit_resi')\n",
    "\n",
    "\n",
    "# PSM Input(Shot별 RK값)을 fitting하고 residual_x에서 빼주기 \n",
    "df_psm_de = psm_decorrect(df_residata, df_psm_input)\n",
    "\n",
    "\n",
    "# mrc_de 결과를 엑셀 파일에 저장\n",
    "with pd.ExcelWriter('output.xlsx', engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    df_psm_de.to_excel(writer, sheet_name='PSM_decorrect', index=False)\n",
    "\n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'PSM Decorrect 완료.' )\n",
    "\n",
    "\n",
    "\n",
    "################################### Resi_depsm을 CPE 38para 모델링 #####################################################################\n",
    "\n",
    "# 데이타 불러오기 \n",
    "df_resi_depsm = pd.read_excel('output.xlsx', sheet_name='PSM_decorrect')\n",
    "\n",
    "\n",
    "# CPE 38para 계산\n",
    "df_cpe19p = resi_to_cpe(df_resi_depsm)\n",
    "\n",
    "\n",
    "# 결과를 엑셀 파일에 저장\n",
    "with pd.ExcelWriter(\"output.xlsx\", engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    df_cpe19p.to_excel(writer, sheet_name='CPE_38p', index=False)\n",
    "\n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'),'CPE 38para Regression 완료.')\n",
    "\n",
    "\n",
    "\n",
    "################################### CPE 38para를 Fitting #####################################################################\n",
    "\n",
    "# multi_lot_cpe_fitting 함수 사용하여 예측값 계산\n",
    "df_cpe38p_fit_res = cpe38p_fitting(df_resi_depsm, df_cpe19p)\n",
    "\n",
    "\n",
    "# 결과를 엑셀 파일에 저장\n",
    "with pd.ExcelWriter(\"output.xlsx\", engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    df_cpe38p_fit_res.to_excel(writer, sheet_name='CPE38p_fit_res', index=False)\n",
    "\n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'CPE_38para Fitting, Residual 완료.')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), '모든 작업이 완료')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
