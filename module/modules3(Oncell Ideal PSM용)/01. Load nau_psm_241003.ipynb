{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20240920\n",
    "# MODULE/01.4 ★ load_nau_EQPID_추가_240920  를 그대로 카피함. \n",
    "\n",
    "# 20240922 : UNIQUE_ID에 M_TIME 구분자 추가\n",
    " 현재 unique_id : m_time 구분자 없음. \n",
    " 문제점 : 동일wafer가 adi, oco 데이터 둘다 존재하면 에러발생.  (M_STEPSEQ 정보가 없음...ㅜ )\n",
    " 변경점 : unique_id에 m_time 추가함. \n",
    "\n",
    "\n",
    " # 20240922 : M_STEP 정보추가\n",
    " 현재 : M_STEP 정보가 NAU파일 내부에 없음.\n",
    " 문제점 : ADI, OCO 섞여있으면 스텝구분을 못해줌..\n",
    " 변경점 : 파일제목에 있는 M_STEP정보를 끌고 오게 변경 \n",
    "\n",
    " \n",
    "\n",
    " #########################################################################################################\n",
    "\n",
    " # 20241003 \n",
    " copy from  \"01.5 Load nau 정리_240922.ipynb\"\n",
    " Oncell residual로부터 Ideal PSM 을 뽑기 위해 제작\n",
    " \n",
    " 1. PSM 전처리 과정 추가 (nau파일로부터 'PerShorMRC\"시트에서 정보 끌어옴)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B3N049.1_VH075040_VH075030_20240530171740_11.nau 파일 읽기 성공\n",
      "B3N049.1_VH075040_VH075030_20240530171740_11.nau 파일에 새로운 시트 추가 완료\n",
      "PDS211.1_WF075040_WF075030_20240716235504_11.nau 파일 읽기 성공\n",
      "PDS211.1_WF075040_WF075030_20240716235504_11.nau 파일에 새로운 시트 추가 완료\n",
      "PRQ328.1_WC046040_WC046030_20240430002132_11.nau 파일 읽기 성공\n",
      "PRQ328.1_WC046040_WC046030_20240430002132_11.nau 파일에 새로운 시트 추가 완료\n",
      "2024-10-03 20:41:56 nau파일 전처리 시작.\n",
      "2024-10-03 20:42:01 nau파일 전처리 완료.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from openpyxl import load_workbook\n",
    "import openpyxl\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# nau 파일이 있는 폴더 경로\n",
    "folder_path = 'C:/py_data/nau'\n",
    "\n",
    "\n",
    "################################################ NAU파일제목에서 M_STEP정보 끌어와서 시트에 저장  ########################################\n",
    "\n",
    "# 폴더 내의 모든 파일에 대해 실행\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # 파일 경로 설정\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # 파일인지 확인 (폴더는 제외)\n",
    "    if os.path.isfile(file_path) and file_name.endswith('.nau'):\n",
    "        try:\n",
    "            # 파일 확장자를 임시로 .xlsx로 변경\n",
    "            temp_file_path = file_path.replace('.nau', '.xlsx')\n",
    "            os.rename(file_path, temp_file_path)\n",
    "\n",
    "            # pandas를 이용해 엑셀 파일(유사)을 읽기\n",
    "            excel_data = pd.read_excel(temp_file_path, engine='openpyxl')\n",
    "            print(f\"{file_name} 파일 읽기 성공\")\n",
    "\n",
    "            # 파일명을 \"_\" 기준으로 분할\n",
    "            file_name_without_extension = os.path.splitext(file_name)[0]\n",
    "            split_file_name = file_name_without_extension.split(\"_\")\n",
    "\n",
    "            # 기존 엑셀 파일 열기\n",
    "            workbook = load_workbook(temp_file_path)\n",
    "\n",
    "            # 파일명 시트를 첫 번째로 추가\n",
    "            new_sheet_name = \"FileName\"\n",
    "            if new_sheet_name not in workbook.sheetnames:\n",
    "                new_sheet = workbook.create_sheet(title=new_sheet_name, index=0)  # 첫 번째 시트로 추가\n",
    "            else:\n",
    "                new_sheet = workbook[new_sheet_name]\n",
    "\n",
    "            # 분할된 파일명을 첫 번째 시트에 기록\n",
    "            for col, value in enumerate(split_file_name, start=1):\n",
    "                new_sheet.cell(row=1, column=col, value=value)\n",
    "\n",
    "            # 변경된 파일 저장\n",
    "            workbook.save(temp_file_path)\n",
    "            print(f\"{file_name} 파일에 새로운 시트 추가 완료\")\n",
    "\n",
    "            # 확장자를 다시 .nau로 복원\n",
    "            os.rename(temp_file_path, file_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"{file_name} 파일을 읽는 중 에러 발생: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################ NAU로부터 필요데이터 추출 (전처리) ########################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 추출할 컬럼 위치 설정 (예: 첫 번째 열은 0, 두 번째 열은 1로 인덱스 시작)\n",
    "columns_to_extract = [0, 1, 2, 3, 4, 5, 6, 7]  # Wafer, TEST, DieX, DieY, X_reg, Y_reg, MRC_X, MRC_Y의 열 위치\n",
    "\n",
    "def process_nau_files(folder_path, columns_to_extract):\n",
    "    # 결과를 담을 리스트 생성\n",
    "    combined_rawdata_list = []\n",
    "    combined_trocs_input_list = []\n",
    "    mrc_data_list = []\n",
    "    combined_psm_input_list = []\n",
    "\n",
    "    # 폴더 내 모든 nau 파일에 대해 반복\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.nau'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            \n",
    "            # 필요한 시트만 읽기\n",
    "            rawdata_file = pd.read_excel(file_path, sheet_name='RawData-1')\n",
    "            trocs_input_file = pd.read_excel(file_path, sheet_name='Trocs Input')\n",
    "            psm_input_file = pd.read_excel(file_path, sheet_name='PerShotMRC')\n",
    "\n",
    "            ########### m_step 시트 불러오기 #########################\n",
    "            m_step_file = pd.read_excel(file_path, sheet_name='FileName')\n",
    "\n",
    "            ######################################## RawData-1 전처리 ##################################################\n",
    "            # 지정된 열 추출\n",
    "            extracted_data_raw = rawdata_file.iloc[:, columns_to_extract].copy()\n",
    "\n",
    "            # 'LOT_ID' 값 및 'STEPSEQ' 추출\n",
    "            lot_id_value_raw = rawdata_file.columns[13]\n",
    "            stepseq_value_raw = rawdata_file.iloc[0, 13]\n",
    "            wafer_value_raw = rawdata_file.iloc[0, 0]\n",
    "            p_eqpid__value_raw = rawdata_file.iloc[1, 13]\n",
    "            photo_ppid_value_raw = rawdata_file.iloc[11, 13]\n",
    "            p_time_value_raw = rawdata_file.iloc[2, 13]\n",
    "            m_time_value_raw = rawdata_file.iloc[4, 13]\n",
    "            chuckid_value_raw = rawdata_file.iloc[15, 13]\n",
    "\n",
    "            # 'm_step' 값 추출 및 신규컬럼 추가\n",
    "            m_step_value_raw = m_step_file.columns[1]\n",
    "            extracted_data_raw['M_STEP'] = m_step_value_raw\n",
    "\n",
    "                \n",
    "            # 새로운 컬럼 추가\n",
    "            extracted_data_raw['STEPSEQ'] = stepseq_value_raw\n",
    "            extracted_data_raw['LOT_ID'] = lot_id_value_raw\n",
    "\n",
    "            # 추가 정보 추출 및 컬럼 추가\n",
    "            extracted_data_raw['STEP_PITCH_X'] = rawdata_file.iloc[6, 13]\n",
    "            extracted_data_raw['STEP_PITCH_Y'] = rawdata_file.iloc[7, 13]\n",
    "            extracted_data_raw['MAP_SHIFT_X'] = rawdata_file.iloc[8, 13]\n",
    "            extracted_data_raw['MAP_SHIFT_Y'] = rawdata_file.iloc[9, 13]\n",
    "\n",
    "            # 'coordinate_X', 'coordinate_Y' 매핑\n",
    "            coord_map = rawdata_file[['Test No', 'coordinate_X', 'coordinate_Y']].drop_duplicates(subset='Test No').set_index('Test No')\n",
    "            extracted_data_raw['coordinate_X'] = extracted_data_raw['TEST'].map(coord_map['coordinate_X'])\n",
    "            extracted_data_raw['coordinate_Y'] = extracted_data_raw['TEST'].map(coord_map['coordinate_Y'])\n",
    "                  \n",
    "            # 'wf_x' 및 'wf_y' 계산\n",
    "            extracted_data_raw['wf_x'] = (\n",
    "                extracted_data_raw['DieX'] * extracted_data_raw['STEP_PITCH_X'] +\n",
    "                extracted_data_raw['MAP_SHIFT_X'] + extracted_data_raw['coordinate_X']\n",
    "            )\n",
    "            extracted_data_raw['wf_y'] = (\n",
    "                extracted_data_raw['DieY'] * extracted_data_raw['STEP_PITCH_Y'] +\n",
    "                extracted_data_raw['MAP_SHIFT_Y'] + extracted_data_raw['coordinate_Y']\n",
    "            )\n",
    "\n",
    "            ##### context 정보추가 #####\n",
    "            extracted_data_raw['P_EQPID'] = rawdata_file.iloc[1, 13]\n",
    "            extracted_data_raw['P_TIME'] = rawdata_file.iloc[2, 13]\n",
    "            extracted_data_raw['M_TIME'] = rawdata_file.iloc[4, 13]\n",
    "            extracted_data_raw['Photo_PPID'] = rawdata_file.iloc[11, 13]\n",
    "            extracted_data_raw['Base_EQP1'] = rawdata_file.iloc[12, 13]\n",
    "            extracted_data_raw['ChuckID'] = rawdata_file.iloc[15, 13]\n",
    "            extracted_data_raw['ReticleID'] = rawdata_file.iloc[16, 13]\n",
    "            \n",
    "            \n",
    "\n",
    "            ######## 'Unique_ID'라는 새로운 컬럼 추가   ########  \n",
    "            ## M_TIME 추가(240922)\n",
    "\n",
    "            extracted_data_raw['UNIQUE_ID'] = extracted_data_raw.apply(\n",
    "                lambda row: f\"{row['STEPSEQ']}_{row['P_EQPID']}_{row['Photo_PPID']}_{row['P_TIME']}_{row['M_STEP']}_{row['M_TIME']}_{row['LOT_ID']}_{row['Wafer']}\", axis=1)\n",
    "\n",
    "\n",
    "            # 'Unique_ID2 추가 (TEST, DieX, DieY 추가. 정렬용)\n",
    "            extracted_data_raw['UNIQUE_ID2'] = extracted_data_raw.apply(\n",
    "                lambda row: f\"{row['STEPSEQ']}_{row['P_EQPID']}_{row['Photo_PPID']}_{row['P_TIME']}_{row['M_STEP']}_{row['M_TIME']}_{row['LOT_ID']}_{row['Wafer']}_{row['TEST']}_{row['DieX']}_{row['DieY']} \", axis=1)\n",
    "            \n",
    "                       \n",
    "\n",
    "\n",
    "\n",
    "            # 컬럼 순서 재조정\n",
    "            cols_order = [\n",
    "                'UNIQUE_ID', 'UNIQUE_ID2',\n",
    "                'STEPSEQ', 'LOT_ID', 'Wafer', \n",
    "                'P_EQPID', 'Photo_PPID', 'P_TIME', 'M_STEP', 'M_TIME', 'ChuckID', 'ReticleID', 'Base_EQP1', \n",
    "                'TEST', 'DieX', 'DieY',\n",
    "                'X_reg', 'Y_reg', 'MRC_X', 'MRC_Y', \n",
    "                'STEP_PITCH_X', 'STEP_PITCH_Y', 'MAP_SHIFT_X', 'MAP_SHIFT_Y', 'coordinate_X', 'coordinate_Y', 'wf_x', 'wf_y'\n",
    "            ]\n",
    "            extracted_data_raw = extracted_data_raw[cols_order]\n",
    "\n",
    "            # 리스트에 추가\n",
    "            combined_rawdata_list.append(extracted_data_raw)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            ######################################## Trocs Input 전처리 ##################################################\n",
    "\n",
    "            trocs_input_file['STEPSEQ'] = stepseq_value_raw\n",
    "            trocs_input_file['LOT_ID'] = lot_id_value_raw\n",
    "            trocs_input_file['Wafer'] = wafer_value_raw\n",
    "            trocs_input_file['P_EQPID'] = p_eqpid__value_raw\n",
    "            trocs_input_file['Photo_PPID'] = photo_ppid_value_raw\n",
    "            trocs_input_file['P_TIME'] = p_time_value_raw \n",
    "            trocs_input_file['M_TIME'] = m_time_value_raw \n",
    "            trocs_input_file['ChuckID'] = chuckid_value_raw\n",
    "            \n",
    "            # 'm_step' 신규컬럼 추가\n",
    "            trocs_input_file['M_STEP'] = m_step_value_raw \n",
    "\n",
    "         \n",
    "            # Trocs Input 데이터프레임에 'Unique_ID'라는 새로운 컬럼 추가\n",
    "            trocs_input_file['UNIQUE_ID'] = trocs_input_file.apply(\n",
    "                lambda row: f\"{row['STEPSEQ']}_{row['P_EQPID']}_{row['Photo_PPID']}_{row['P_TIME']}_{row['M_STEP']}_{row['M_TIME']}_{row['LOT_ID']}_{row['Wafer']}\", axis=1)\n",
    "\n",
    "            # 'Unique_ID2 추가 (DieX(=dCol), DieY(=dRow) 추가. 정렬용)\n",
    "            trocs_input_file['UNIQUE_ID2'] = trocs_input_file.apply(\n",
    "                lambda row: f\"{row['STEPSEQ']}_{row['P_EQPID']}_{row['Photo_PPID']}_{row['P_TIME']}_{row['M_STEP']}_{row['M_TIME']}_{row['LOT_ID']}_{row['Wafer']}_{row['dCol']}_{row['dRow']}\", axis=1)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            # 순서 재조정\n",
    "            # 기존 컬럼 뒤로 밀기 - 순서를 맨 앞으로 추가하는 순서로 재배열\n",
    "            cols_to_insert = ['UNIQUE_ID', 'UNIQUE_ID2', 'STEPSEQ', 'LOT_ID', 'Wafer', 'P_EQPID', 'Photo_PPID', 'P_TIME', 'M_STEP','M_TIME', 'ChuckID']\n",
    "\n",
    "            # 각 컬럼을 지정된 위치에 삽입 (맨 앞에)\n",
    "            for i, col in enumerate(cols_to_insert):\n",
    "                trocs_input_file.insert(i, col, trocs_input_file.pop(col))\n",
    "\n",
    "            # 리스트에 추가\n",
    "            combined_trocs_input_list.append(trocs_input_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            ######################################## MRC 전처리 ##################################################\n",
    "\n",
    "            \n",
    "            # MRC 데이터 추출을 위해 'RawData-1' 시트를 header=None으로 다시 읽음\n",
    "            rawdata_file_no_header = pd.read_excel(file_path, sheet_name='RawData-1', header=None)\n",
    "\n",
    "            # MRC 데이터 추출\n",
    "            mrc_part1 = rawdata_file_no_header.iloc[0:20, 15:17]\n",
    "            mrc_part2 = rawdata_file_no_header.iloc[22:40, 15:17]\n",
    "            mrc_part = pd.concat([mrc_part1, mrc_part2], ignore_index=True)\n",
    "\n",
    "            # 컬럼 이름 설정\n",
    "            mrc_part.columns = ['K PARA', 'GPM']\n",
    "\n",
    "            # INDEX 컬럼 추가 (1부터 시작하는 순차적 번호)\n",
    "            mrc_part['INDEX'] = range(1, len(mrc_part) + 1)\n",
    "\n",
    "\n",
    "            # 컬럼 추가             \n",
    "            mrc_part['STEPSEQ'] = stepseq_value_raw\n",
    "            mrc_part['LOT_ID'] = lot_id_value_raw\n",
    "            mrc_part['Wafer'] = wafer_value_raw\n",
    "            mrc_part['P_EQPID'] = p_eqpid__value_raw\n",
    "            mrc_part['Photo_PPID'] = photo_ppid_value_raw\n",
    "            mrc_part['P_TIME'] = p_time_value_raw \n",
    "            mrc_part['M_TIME'] = m_time_value_raw \n",
    "            mrc_part['ChuckID'] = chuckid_value_raw\n",
    "\n",
    "            # 'm_step' 신규컬럼 추가\n",
    "            mrc_part['M_STEP'] = m_step_value_raw \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # mrc_part 데이터프레임에 'Unique_ID'라는 새로운 컬럼 추가\n",
    "            mrc_part['UNIQUE_ID'] = mrc_part.apply(\n",
    "                lambda row: f\"{row['STEPSEQ']}_{row['P_EQPID']}_{row['Photo_PPID']}_{row['P_TIME']}_{row['M_STEP']}_{row['M_TIME']}_{row['LOT_ID']}_{row['Wafer']}\", axis=1)\n",
    "\n",
    "\n",
    "            # 컬럼 순서 재조정\n",
    "            mrc_cols_order = [\n",
    "                'UNIQUE_ID',\n",
    "                'STEPSEQ', 'LOT_ID', 'Wafer', \n",
    "                'P_EQPID', 'Photo_PPID', 'P_TIME', 'M_STEP','M_TIME', 'ChuckID',  \n",
    "                'K PARA', 'GPM', 'INDEX'\n",
    "            ]\n",
    "            mrc_part = mrc_part[mrc_cols_order]\n",
    "\n",
    "            \n",
    "            # 리스트에 추가\n",
    "            mrc_data_list.append(mrc_part)\n",
    "\n",
    "            \n",
    "            ######################################## PSM 전처리 ##################################################\n",
    "\n",
    "            psm_input_file['STEPSEQ'] = stepseq_value_raw\n",
    "            psm_input_file['LOT_ID'] = lot_id_value_raw\n",
    "            psm_input_file['Wafer'] = wafer_value_raw\n",
    "            psm_input_file['P_EQPID'] = p_eqpid__value_raw\n",
    "            psm_input_file['Photo_PPID'] = photo_ppid_value_raw\n",
    "            psm_input_file['P_TIME'] = p_time_value_raw \n",
    "            psm_input_file['M_TIME'] = m_time_value_raw \n",
    "            psm_input_file['ChuckID'] = chuckid_value_raw\n",
    "\n",
    "            # 'm_step' 신규컬럼 추가\n",
    "            psm_input_file['M_STEP'] = m_step_value_raw \n",
    "\n",
    "            # PSM Input 데이터프레임에 'Unique_ID'라는 새로운 컬럼 추가\n",
    "            psm_input_file['UNIQUE_ID'] = psm_input_file.apply(\n",
    "                lambda row: f\"{row['STEPSEQ']}_{row['P_EQPID']}_{row['Photo_PPID']}_{row['P_TIME']}_{row['M_STEP']}_{row['M_TIME']}_{row['LOT_ID']}_{row['Wafer']}\", axis=1)\n",
    "\n",
    "            # 'Unique_ID2 추가 (DieX(=dCol), DieY(=dRow) 추가. 정렬용)\n",
    "            psm_input_file['UNIQUE_ID2'] = psm_input_file.apply(\n",
    "                lambda row: f\"{row['STEPSEQ']}_{row['P_EQPID']}_{row['Photo_PPID']}_{row['P_TIME']}_{row['M_STEP']}_{row['M_TIME']}_{row['LOT_ID']}_{row['Wafer']}_{row['dCol']}_{row['dRow']}\", axis=1)\n",
    "            \n",
    "            \n",
    "            # 순서 재조정\n",
    "            # 기존 컬럼 뒤로 밀기 - 순서를 맨 앞으로 추가하는 순서로 재배열\n",
    "            cols_to_insert_psm = ['UNIQUE_ID', 'UNIQUE_ID2', 'STEPSEQ', 'LOT_ID', 'Wafer', 'P_EQPID', 'Photo_PPID', 'P_TIME', 'M_STEP','M_TIME', 'ChuckID']\n",
    "\n",
    "            # 각 컬럼을 지정된 위치에 삽입 (맨 앞에)\n",
    "            for i, col in enumerate(cols_to_insert_psm):\n",
    "                psm_input_file.insert(i, col, psm_input_file.pop(col))\n",
    "\n",
    "            # 리스트에 추가\n",
    "            combined_psm_input_list.append(psm_input_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 리스트를 데이터프레임으로 병합\n",
    "    combined_rawdata = pd.concat(combined_rawdata_list, ignore_index=True)\n",
    "    combined_trocs_input = pd.concat(combined_trocs_input_list, ignore_index=True)\n",
    "    mrc_data = pd.concat(mrc_data_list, ignore_index=True)\n",
    "    combined_psm_input = pd.concat(combined_psm_input_list, ignore_index=True)\n",
    "\n",
    "    # 병합 후, UNIQUE_ID기준으로 오름차순 정렬 (내림차순하고 싶으면 ascending=False 옵션 추가하면 됨.) \n",
    "    combined_rawdata = combined_rawdata.sort_values(by=['UNIQUE_ID', 'TEST', 'DieX', 'DieY'])    \n",
    "    combined_trocs_input = combined_trocs_input.sort_values(by=['UNIQUE_ID', 'dCol', 'dRow'])\n",
    "    mrc_data = mrc_data.sort_values(by=['UNIQUE_ID', 'INDEX'])\n",
    "    combined_psm_input = combined_psm_input.sort_values(by=['UNIQUE_ID', 'dCol', 'dRow'])\n",
    "\n",
    "\n",
    "    # 최종 데이터를 엑셀 파일로 저장\n",
    "    with pd.ExcelWriter('output.xlsx') as writer:\n",
    "        combined_rawdata.to_excel(writer, sheet_name='RawData-1', index=False)\n",
    "        combined_trocs_input.to_excel(writer, sheet_name='Trocs Input', index=False)\n",
    "        mrc_data.to_excel(writer, sheet_name='MRC', index=False)\n",
    "        combined_psm_input.to_excel(writer, sheet_name='PerShotMRC', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################### nau 파일 처리 및 데이터 저장 #####################################################################\n",
    "\n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'nau파일 전처리 시작.')\n",
    "process_nau_files(folder_path, columns_to_extract)\n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'nau파일 전처리 완료.')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
